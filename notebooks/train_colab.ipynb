{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cgvwno064Jb"
      },
      "outputs": [],
      "source": [
        "!gdown 1UzC3NCDj30j9Ba7i5lkMzWO5gFqSr0OJ\n",
        "!unzip PMEmo2019.zip\n",
        "!rm -rf ./__MACOSX\n",
        "!rm -rf ./PMEmo2019.zip\n",
        "\n",
        "!git clone https://github.com/rxng8/Music-Emotion-Recognition-Research.git\n",
        "\n",
        "!mkdir ./Music-Emotion-Recognition-Research/data/PMEmo2019\n",
        "!mv ./PMEmo2019 ./Music-Emotion-Recognition-Research/data/PMEmo2019\n",
        "\n",
        "%cd ./Music-Emotion-Recognition-Research/\n",
        "\n",
        "!sudo apt-get install libportaudio2\n",
        "!apt install ffmpeg\n",
        "\n",
        "!pip install -r ./requirements.txt\n",
        "\n",
        "!python ./old/wav_converter.py \"./data/PMEmo2019/PMEmo2019/chorus\" \"./data/PMEmo2019/PMEmo2019/chorus_wav\" ffmpeg\n",
        "\n",
        "!rm -rf ./configs/config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKMZrSlnrCNy",
        "outputId": "67da13fe-3997-4614-dacd-d614bc205180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./configs/config.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./configs/config.json\n",
        "{\n",
        "  \"DEFAULT_FREQ\": 44100,\n",
        "  \"DEFAULT_TIME\": 40,\n",
        "  \"WINDOW_TIME\": 5,\n",
        "  \"TRAIN_RATIO\": 0.8,\n",
        "  \"BATCH_SIZE\": 16,\n",
        "  \"FREQUENCY_LENGTH\": 129,\n",
        "  \"N_CHANNEL\": 1,\n",
        "  \"SPECTROGRAM_TIME_LENGTH\": 15502,\n",
        "  \"SPECTROGRAM_HALF_SECOND_LENGTH\": 171,\n",
        "  \"SPECTROGRAM_5_SECOND_LENGTH\": 1721,\n",
        "  \"MFCCS_TIME_LENGTH\": 3876,\n",
        "  \"LEARNING_RATE\": 1e-4,\n",
        "  \"SOUND_EXTENSION\": \".wav\",\n",
        "  \"MIN_TIME_END_POINT\": 15,\n",
        "  \"AUDIO_FOLDER\": \"./data/PMEmo2019/PMEmo2019/chorus_wav\",\n",
        "  \"ANNOTATION_SONG_LEVEL\": [\n",
        "    \"./data/PMEmo2019/PMEmo2019/annotations/static_annotations.csv\",\n",
        "    \"./data/PMEmo2019/PMEmo2019/annotations/static_annotations_std.csv\"\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkshLJ-G7eEk",
        "outputId": "cb454442-0ada-4742-fb23-5f3bdd08482c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.8.0\n",
            "Num GPUs Available:  0\n",
            "Munch({'DEFAULT_FREQ': 44100, 'DEFAULT_TIME': 40, 'WINDOW_TIME': 5, 'TRAIN_RATIO': 0.8, 'BATCH_SIZE': 16, 'FREQUENCY_LENGTH': 129, 'N_CHANNEL': 1, 'SPECTROGRAM_TIME_LENGTH': 15502, 'SPECTROGRAM_HALF_SECOND_LENGTH': 171, 'SPECTROGRAM_5_SECOND_LENGTH': 1721, 'MFCCS_TIME_LENGTH': 3876, 'LEARNING_RATE': 0.0001, 'SOUND_EXTENSION': '.wav', 'MIN_TIME_END_POINT': 15, 'AUDIO_FOLDER': './data/PMEmo2019/PMEmo2019/chorus_wav', 'ANNOTATION_SONG_LEVEL': ['./data/PMEmo2019/PMEmo2019/annotations/static_annotations.csv', './data/PMEmo2019/PMEmo2019/annotations/static_annotations_std.csv'], 'WAVE_ARRAY_LENGTH': 1764000, 'WINDOW_SIZE': 220500})\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@Creator: Viet Dung Nguyen\n",
        "@Date: April 14, 2022\n",
        "@Credits: Viet Dung Nguyen\n",
        "@Version: 0.0.1\n",
        "\n",
        "Example notebook file\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "from tensorflow.python.keras import layers as L\n",
        "from tensorflow.python.keras.models import Model\n",
        "\n",
        "from mer.mer.utils.const import get_config_from_json, setup_global_config\n",
        "\n",
        "# Argument parsing\n",
        "config_path = \"./configs/config.json\"\n",
        "config = get_config_from_json(config_path)\n",
        "\n",
        "##### Workaround to setup global config ############\n",
        "setup_global_config(config, verbose=True)\n",
        "from mer.mer.utils.const import GLOBAL_CONFIG\n",
        "##### End of Workaround #####\n",
        "\n",
        "# Because the generator and some classes are based on the\n",
        "# GLOBAL_CONFIG, we have to import them after we set the config\n",
        "from mer.mer.utils.utils import load_metadata, split_train_test, \\\n",
        "  preprocess_waveforms, get_spectrogram, plot_and_play, \\\n",
        "  pad_waveforms, plot_wave\n",
        "from mer.mer.model import get_rnn_model,get_rnn_model_2, Simple_CRNN_3\n",
        "from mer.mer.optimizer import get_Adam_optimizer, get_SGD_optimizer\n",
        "from mer.mer.loss import simple_mae_loss, simple_mse_loss\n",
        "from mer.mer.feature import load_wave_data, extract_spectrogram_features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2hBAEhyJ7oYB",
        "outputId": "e6ba4115-cd72-4b40-b193-00cc89614038"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c111d8fe-271a-4fc3-a72a-074b11d9ccc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>musicId</th>\n",
              "      <th>Arousal(mean)</th>\n",
              "      <th>Valence(mean)</th>\n",
              "      <th>Arousal(std)</th>\n",
              "      <th>Valence(std)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.5750</td>\n",
              "      <td>0.156125</td>\n",
              "      <td>0.160078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0.2625</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.152582</td>\n",
              "      <td>0.158607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.203101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.3500</td>\n",
              "      <td>0.171847</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.7250</td>\n",
              "      <td>0.139194</td>\n",
              "      <td>0.122474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>993</td>\n",
              "      <td>0.8625</td>\n",
              "      <td>0.7625</td>\n",
              "      <td>0.103833</td>\n",
              "      <td>0.152582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>996</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.111803</td>\n",
              "      <td>0.245268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>997</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>0.6625</td>\n",
              "      <td>0.177218</td>\n",
              "      <td>0.112500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>999</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.7750</td>\n",
              "      <td>0.096825</td>\n",
              "      <td>0.122474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1000</td>\n",
              "      <td>0.6625</td>\n",
              "      <td>0.5750</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.210654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>767 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c111d8fe-271a-4fc3-a72a-074b11d9ccc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c111d8fe-271a-4fc3-a72a-074b11d9ccc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c111d8fe-271a-4fc3-a72a-074b11d9ccc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     musicId  Arousal(mean)  Valence(mean)  Arousal(std)  Valence(std)\n",
              "0          1         0.4000         0.5750      0.156125      0.160078\n",
              "1          4         0.2625         0.2875      0.152582      0.158607\n",
              "2          5         0.1500         0.2000      0.175000      0.203101\n",
              "3          6         0.5125         0.3500      0.171847      0.200000\n",
              "4          7         0.7000         0.7250      0.139194      0.122474\n",
              "..       ...            ...            ...           ...           ...\n",
              "762      993         0.8625         0.7625      0.103833      0.152582\n",
              "763      996         0.8750         0.5625      0.111803      0.245268\n",
              "764      997         0.7125         0.6625      0.177218      0.112500\n",
              "765      999         0.8750         0.7750      0.096825      0.122474\n",
              "766     1000         0.6625         0.5750      0.137500      0.210654\n",
              "\n",
              "[767 rows x 5 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# %%%\n",
        "filenames = tf.io.gfile.glob(str(GLOBAL_CONFIG.AUDIO_FOLDER) + '/*')\n",
        "# Process with average annotation per song. \n",
        "\n",
        "df = load_metadata(GLOBAL_CONFIG.ANNOTATION_SONG_LEVEL)\n",
        "\n",
        "# Smaller set of data\n",
        "# df = df[:64]\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F1uy2txr9Ncl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %%\n",
        "\n",
        "train_df, test_df = split_train_test(df, GLOBAL_CONFIG.TRAIN_RATIO)\n",
        "\n",
        "# %%\n",
        "\n",
        "# song_path = \"../data/PMEmo/PMEmo2019/PMEmo2019/chorus_wav/6.wav\"\n",
        "\n",
        "# lib_wave, sr = librosa.load(song_path, GLOBAL_CONFIG.DEFAULT_FREQ)\n",
        "# lib_wave = tf.convert_to_tensor(lib_wave)[..., tf.newaxis]\n",
        "\n",
        "# plot_wave(lib_wave, second_length=40)\n",
        "\n",
        "\n",
        "# audio_file = tf.io.read_file(song_path)\n",
        "\n",
        "# waveforms, sample_rate = tf.audio.decode_wav(contents=audio_file)\n",
        "\n",
        "\n",
        "# def plot_wave_4(waveforms, second_id = 0, second_length = 10, channel = 0):\n",
        "#   from_id = int(44100 * second_id)\n",
        "#   to_id = min(int(44100 * (second_id + second_length)), waveforms.shape[0])\n",
        "\n",
        "#   fig, axes = plt.subplots(1, figsize=(12, 4))\n",
        "#   timescale = np.arange(to_id - from_id)\n",
        "#   axes.plot(timescale, waveforms[from_id:to_id, channel].numpy())\n",
        "#   axes.set_title('Waveform')\n",
        "#   axes.set_xlim([0, int(44100 * second_length)])\n",
        "#   plt.show()\n",
        "\n",
        "# plot_wave_4(waveforms, second_length=40)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "szBTGqli9SSi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %%\n",
        "\n",
        "def train_datagen():\n",
        "  \"\"\" Predicting valence mean and arousal mean\n",
        "  \"\"\"\n",
        "  pointer = 0\n",
        "  while True:\n",
        "    # Reset pointer\n",
        "    if pointer >= len(train_df):\n",
        "      pointer = 0\n",
        "\n",
        "    row = train_df.loc[pointer]\n",
        "    song_id = row[\"musicId\"]\n",
        "    arousal_mean = float(row[\"Arousal(mean)\"])\n",
        "    valence_mean = float(row[\"Valence(mean)\"])\n",
        "    \n",
        "    # TODO: HOw are we gonna integrate valence and arousal std?\n",
        "    arousal_std = float(row[\"Arousal(std)\"])\n",
        "    valence_std = float(row[\"Valence(std)\"])\n",
        "    \n",
        "    label = tf.convert_to_tensor([valence_mean, arousal_mean, valence_std, arousal_std], dtype=tf.float32)\n",
        "    song_path = os.path.join(GLOBAL_CONFIG.AUDIO_FOLDER, str(int(song_id)) + GLOBAL_CONFIG.SOUND_EXTENSION)\n",
        "    \n",
        "    waveforms = load_wave_data(song_path)\n",
        "    \n",
        "    spectrogram_features = extract_spectrogram_features(waveforms)\n",
        "    \n",
        "    # Preprocessed and normalize waveforms in the end\n",
        "    waveforms = preprocess_waveforms(waveforms)\n",
        "\n",
        "    # Update pointer\n",
        "    pointer += 1\n",
        "    yield (waveforms, spectrogram_features, label)\n",
        "\n",
        "def test_datagen():\n",
        "  \"\"\" Predicting valence mean and arousal mean\n",
        "  \"\"\"\n",
        "  pointer = 0\n",
        "  while True:\n",
        "    # Reset pointer\n",
        "    if pointer >= len(test_df):\n",
        "      pointer = 0\n",
        "\n",
        "    row = test_df.loc[pointer]\n",
        "    song_id = row[\"musicId\"]\n",
        "    valence_mean = float(row[\"Valence(mean)\"])\n",
        "    arousal_mean = float(row[\"Arousal(mean)\"])\n",
        "    arousal_std = float(row[\"Arousal(std)\"])\n",
        "    valence_std = float(row[\"Valence(std)\"])\n",
        "    label = tf.convert_to_tensor([valence_mean, arousal_mean, valence_std, arousal_std], dtype=tf.float32)\n",
        "    song_path = os.path.join(GLOBAL_CONFIG.AUDIO_FOLDER, str(int(song_id)) + GLOBAL_CONFIG.SOUND_EXTENSION)\n",
        "\n",
        "    waveforms = load_wave_data(song_path)\n",
        "    \n",
        "    spectrogram_features = extract_spectrogram_features(waveforms)\n",
        "    \n",
        "    # Preprocessed and normalize waveforms in the end\n",
        "    waveforms = preprocess_waveforms(waveforms)\n",
        "\n",
        "    pointer += 1\n",
        "    yield (waveforms, spectrogram_features, label)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "  train_datagen,\n",
        "  output_signature=(\n",
        "    tf.TensorSpec(shape=(GLOBAL_CONFIG.WAVE_ARRAY_LENGTH, GLOBAL_CONFIG.N_CHANNEL), dtype=tf.float32),\n",
        "    tf.TensorSpec(shape=(GLOBAL_CONFIG.SPECTROGRAM_TIME_LENGTH, GLOBAL_CONFIG.FREQUENCY_LENGTH, GLOBAL_CONFIG.N_CHANNEL), dtype=tf.float32),\n",
        "    tf.TensorSpec(shape=(4), dtype=tf.float32)\n",
        "  )\n",
        ")\n",
        "train_batch_dataset = train_dataset.batch(GLOBAL_CONFIG.BATCH_SIZE)\n",
        "# train_batch_dataset = train_batch_dataset.cache().prefetch(tf.data.AUTOTUNE) # OOM error\n",
        "train_batch_iter = iter(train_batch_dataset)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "  test_datagen,\n",
        "  output_signature=(\n",
        "    tf.TensorSpec(shape=(GLOBAL_CONFIG.WAVE_ARRAY_LENGTH, GLOBAL_CONFIG.N_CHANNEL), dtype=tf.float32),\n",
        "    tf.TensorSpec(shape=(GLOBAL_CONFIG.SPECTROGRAM_TIME_LENGTH, GLOBAL_CONFIG.FREQUENCY_LENGTH, GLOBAL_CONFIG.N_CHANNEL), dtype=tf.float32),\n",
        "    tf.TensorSpec(shape=(4), dtype=tf.float32)\n",
        "  )\n",
        ")\n",
        "test_batch_dataset = test_dataset.batch(GLOBAL_CONFIG.BATCH_SIZE)\n",
        "# test_batch_dataset = test_batch_dataset.cache().prefetch(tf.data.AUTOTUNE) # OOM error\n",
        "test_batch_iter = iter(test_batch_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeDHjfH69XAP",
        "outputId": "f7806283-a81c-4874-8bf4-c0b9e36c51bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 1764000, 1)\n",
            "(16, 15502, 129, 1)\n",
            "(16, 4)\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# test data gen\n",
        "\n",
        "in_wave, in_spec, out = next(test_batch_iter)\n",
        "print(in_wave.shape)\n",
        "print(in_spec.shape)\n",
        "print(out.shape)\n",
        "\n",
        "# plot_wave(in_wave[0], second_id = 0, second_length = 40, channel = 0)\n",
        "# plot_and_play(in_wave[5], second_id = 0, second_length = 40, channel = 0)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LucHgWk39Z4o",
        "outputId": "5f89acf5-4b82-46ed-86f8-2fae7ae97844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 15502, 129, 1)]   0         \n",
            "_________________________________________________________________\n",
            "permute (Permute)            (None, 129, 15502, 1)     0         \n",
            "_________________________________________________________________\n",
            "tf.convert_to_tensor (TFOpLa (None, 129, 15502, 1)     0         \n",
            "_________________________________________________________________\n",
            "tf.image.resize (TFOpLambda) (None, 129, 2048, 1)      0         \n",
            "_________________________________________________________________\n",
            "tf.cast (TFOpLambda)         (None, 129, 2048, 1)      0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 125, 2044, 64)     1664      \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 125, 2044, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 125, 2044, 32)     2080      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 125, 2044, 32)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 62, 1022, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 62, 1022, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 58, 1018, 128)     102528    \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 58, 1018, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 58, 1018, 64)      8256      \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 58, 1018, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 29, 509, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 29, 509, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 25, 505, 256)      409856    \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 25, 505, 256)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 25, 505, 128)      32896     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 25, 505, 128)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 252, 128)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 252, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 248, 512)       1638912   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 8, 248, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 248, 256)       131328    \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 8, 248, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 124, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 124, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 122, 1024)      2360320   \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 2, 122, 1024)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 122, 512)       524800    \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 2, 122, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 61, 512)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 61, 512)        0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLa (None, 61, 512)           0         \n",
            "_________________________________________________________________\n",
            "permute_1 (Permute)          (None, 512, 61)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 512, 256)          325632    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 512, 128)          197120    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 5,966,116\n",
            "Trainable params: 5,966,116\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "\n",
        "# model = get_rnn_model()\n",
        "# model.summary()\n",
        "# model_name = \"rnn_1\"\n",
        "# sample_input = tf.ones(shape=(BATCH_SIZE, SPECTROGRAM_TIME_LENGTH, FREQUENCY_LENGTH, 2))\n",
        "# with tf.device(\"/CPU:0\"):\n",
        "#   sample_output = model(sample_input, training=False)\n",
        "# print(sample_output)\n",
        "\n",
        "# model = get_rnn_model_2(input_shape=in_wave.shape[1:])\n",
        "# model.summary()\n",
        "# model_name = \"rnn_2\"\n",
        "\n",
        "model = Simple_CRNN_3(input_shape=in_spec.shape[1:])\n",
        "model.summary()\n",
        "model_name = \"crnn_3\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zJCI_5T_9dfH"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "\n",
        "\n",
        "history_path = f\"./history/{model_name}.npy\"\n",
        "weights_path = f\"./models/{model_name}/checkpoint\"\n",
        "\n",
        "# optimizer = get_SGD_optimizer()\n",
        "optimizer = get_Adam_optimizer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M9yghN09gaN"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "\n",
        "from mer.mer.trainer import Trainer\n",
        "\n",
        "trainer = Trainer(model,\n",
        "  train_batch_iter,\n",
        "  test_batch_iter,\n",
        "  optimizer,\n",
        "  simple_mse_loss,\n",
        "  epochs=10,\n",
        "  steps_per_epoch=45, # // 64 // 16 // //////     724 // 16 = 45\n",
        "  valid_step=5,\n",
        "  history_path=history_path,\n",
        "  weights_path=weights_path,\n",
        "  save_history=True)\n",
        "\n",
        "# About 50 epochs with each epoch step 100 will cover the whole training dataset!\n",
        "history = trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqUndEn796NO"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "\n",
        "from mer.mer.utils.utils import plot_history\n",
        "\n",
        "plot_history(history_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHYA8Co_98Qh"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "\n",
        "def evaluate(df_pointer, model, loss_func, play=False):\n",
        "  row = test_df.loc[df_pointer]\n",
        "  song_id = row[\"musicId\"]\n",
        "  arousal_mean = float(row[\"Arousal(mean)\"])\n",
        "  valence_mean = float(row[\"Valence(mean)\"])\n",
        "  arousal_std = float(row[\"Arousal(std)\"])\n",
        "  valence_std = float(row[\"Valence(std)\"])\n",
        "  label = tf.convert_to_tensor([valence_mean, arousal_mean, valence_std, arousal_std], dtype=tf.float32)\n",
        "  print(f\"Label: Valence: {valence_mean}, Arousal: {arousal_mean}\")\n",
        "  song_path = os.path.join(GLOBAL_CONFIG.AUDIO_FOLDER, str(int(song_id)) + GLOBAL_CONFIG.SOUND_EXTENSION)\n",
        "  waveforms = load_wave_data(song_path)\n",
        "  spectrograms = extract_spectrogram_features(waveforms)[tf.newaxis, ...]\n",
        "  waveforms = preprocess_waveforms(waveforms)\n",
        "\n",
        "  ## Eval\n",
        "  y_pred = model(spectrograms, training=False)[0]\n",
        "\n",
        "  print(y_pred.shape)\n",
        "\n",
        "  print(f\"Predicted y_pred value: Valence: {y_pred[0]}, Arousal: {y_pred[1]}\")\n",
        "\n",
        "  loss = loss_func(label[tf.newaxis, ...], y_pred)\n",
        "  print(f\"Loss: {loss}\")\n",
        "\n",
        "  if play:\n",
        "    plot_and_play(waveforms, 0, 40, 0)\n",
        "\n",
        "i = 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oKKpiNR9-Ny"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "\n",
        "# model.load_weights(weights_path)\n",
        "\n",
        "# %%\n",
        "\n",
        "i += 1\n",
        "evaluate(i, model, simple_mse_loss, play=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
